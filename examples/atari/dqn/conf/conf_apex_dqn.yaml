# Global configs
m_server_name: "m_server"
m_server_addr: "127.0.0.1:4411"

r_server_name: "r_server"
r_server_addr: "127.0.0.1:4412"

c_server_name: "c_server"
c_server_addr: "127.0.0.1:4413"

train_device: "cuda:0"
infer_device: "cuda:1"

env:
  game: "Pong"
  repeat_action_probability: 0.25  # sticky actions
  full_action_space: True
  max_num_frames_per_episode: 108000

seed: null
table_view: False

# Training configs.
num_training_rollouts: 32
num_training_workers: 16

eps: 0.1

replay_buffer_size: 1000000
priority_exponent: 0.6
prefetch: 2

importance_sampling_exponent: 0.4

max_abs_reward: null
rescale_value: True
value_clipping_eps: 0.2

network: "nature"
double_dqn: False
target_sync_period: null

gamma: 0.99
n_step: 5

batch_size: 512
learning_starts: 65536
model_push_period: 10

optimizer:
  name: "Adam"
  lr: 3e-4
  eps: 1e-8

num_epochs: 1000
steps_per_epoch: 10000

# Evaluation configs
num_evaluation_episodes: 10

num_evaluation_rollouts: 4
num_evaluation_workers: 2

evaluation_eps: 1e-3
